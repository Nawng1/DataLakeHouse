services:
  # Kafka and ZooKeeper for streaming data
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - data-lakehouse-network

  kafka:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "flood-warnings:1:1,flood-areas:1:1,water-levels:1:1,stations:1:1,historical-readings:1:1"
      KAFKA_MESSAGE_MAX_BYTES: 20971520  # 20MB
      KAFKA_REPLICA_FETCH_MAX_BYTES: 20971520  # 20MB
      KAFKA_MAX_REQUEST_SIZE: 20971520  # 20MB
    networks:
      - data-lakehouse-network


  spark-master:
    build:
      context: ./docker-image/spark
      dockerfile: ./Dockerfile
    container_name: "spark-master"
    ports:
      - "7077:7077"  # Spark master port
      - "8081:8080"  # Spark master web UI port
    expose: 
      - "7077"
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minio_access_key
      - MINIO_SECRET_KEY=minio_secret_key
    volumes:
      - ./spark-config/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./spark-config/conf/log4j.properties:/opt/bitnami/spark/conf/log4j.properties
      - ./etl-pineline/extract:/opt/bitnami/spark/scripts
      - ./etl-pineline/transform:/opt/bitnami/spark/transform
      - ./ml-flow:/opt/bitnami/spark/ml
    networks:
      - data-lakehouse-network

  spark-worker-1:
    image: docker.io/bitnami/spark:3.3.2
    container_name: "spark-worker-1"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=3G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minio_access_key
      - MINIO_SECRET_KEY=minio_secret_key
    volumes:
      - ./etl-pineline/extract:/opt/bitnami/spark/scripts
      - ./etl-pineline/transform:/opt/bitnami/spark/transform
      - ./etl-pineline/ml:/opt/bitnami/spark/ml
    depends_on:
      - spark-master
    networks:
      - data-lakehouse-network

  spark-notebook:
    build: 
      context: ./docker-image/notebook
      dockerfile: ./Dockerfile
    container_name: "spark-notebook"
    user: root
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - GRANT_SUDO=yes
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000/ 
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
    volumes:
      - ./notebook-config/work:/home/jovyan/work
      - ./notebook-config/conf/spark-defaults.conf:/usr/local/spark/conf/spark-defaults.conf
    ports:
      - "8888:8888"
      - "4040:4040"
    networks:
      - data-lakehouse-network

  trino:
    hostname: trino
    image: 'trinodb/trino:414'
    ports:
      - '8086:8080'
    volumes:
      - ./etc:/usr/lib/trino/etc:ro
    networks:
      - data-lakehouse-network

  mariadb:
    hostname: mariadb
    image: mariadb:10.5.8
    ports:
      - 3306:3306
    environment:
      MYSQL_ROOT_PASSWORD: admin
      MYSQL_USER: admin
      MYSQL_PASSWORD: admin
      MYSQL_DATABASE: metastore_db
    networks:
      - data-lakehouse-network

  hive-metastore:
    hostname: hive-metastore
    image: 'bitsondatadev/hive-metastore:latest'
    ports:
      - '9083:9083' # Metastore Thrift
    volumes:
      - ./docker-image/hive/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    environment:
      METASTORE_DB_HOSTNAME: mariadb
    depends_on:
      - mariadb
    networks:
      - data-lakehouse-network

  minio:
    hostname: minio
    image: minio/minio:RELEASE.2024-05-10T01-41-38Z
    container_name: minio
    ports:
      - '9000:9000'
      - '9001:9001'
    volumes:
      - ./data:/data
    environment:
      MINIO_ROOT_USER: minio_access_key
      MINIO_ROOT_PASSWORD: minio_secret_key
    command: server /data --console-address ":9001"
    networks:
      - data-lakehouse-network

  # Superset for data visualization
  superset:
    image: apache/superset:latest
    container_name: superset
    ports:
      - "8088:8088"
    environment:
      SUPERSET_SECRET_KEY: "superset-secret-key"
      SUPERSET_BIND_ADDRESS: "0.0.0.0"
    volumes:
      - superset-data:/app/superset_home
    depends_on:
      - trino
    networks:
      - data-lakehouse-network
    command: >
      bash -c "superset db upgrade &&
              superset fab create-admin --username admin --firstname Superset --lastname Admin --email admin@superset.com --password admin &&
              superset init &&
              superset run -p 8088 --host 0.0.0.0 --with-threads --reload --debugger"

networks:
  data-lakehouse-network:
    driver: bridge

volumes:
  minio-data:
  hive-data:
  trino-data:
  superset-data:
